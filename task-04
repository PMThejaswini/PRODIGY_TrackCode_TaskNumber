!pip install nltk
import pandas as pd
import numpy as np
from nltk.tokenize import sent_tokenize, word_tokenize
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.datasets import fetch_20newsgroups
from nltk.corpus import stopwords
import string
from nltk import pos_tag
from nltk.stem import WordNetLemmatizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
import pandas as pd 
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline

data=pd.read_csv("C:\\Users\\pmthe\\Downloads\\twitter_training.csv\\twitter_training.csv")
v_data=pd.read_csv("C:\\Users\\pmthe\\Downloads\\twitter_validation.csv")
data

v_data

data.columns= ['id', 'game', 'sentiment', 'text']
v_data.columns= ['id', 'game', 'sentiment', 'text']
data

v_data

data.shape

data.columns

data.describe(include='all')

id_types = data['id'].value_counts()
id_types

plt.figure(figsize=(12,7))
sns.barplot(y=id_types.index, x=id_types.values)
plt.xlabel('Type')
plt.ylabel('Count')
plt.title('# of Id vs Count')
plt.show()

game_types = data['game'].value_counts()
game_types

plt.figure(figsize=(14,10))

sns.barplot(x=game_types.values,y=game_types.index)
plt.title('# of Games and their count')
plt.ylabel('Type')
plt.xlabel('Count')
plt.show()

sns.catplot(x="game",hue="sentiment", kind="count",height=10,aspect=3, data=data)

sns.heatmap(data.isnull(),yticklabels=False,cbar=False,cmap='viridis')

total_null=data.isnull().sum().sort_values(ascending=False)
percent = ((data.isnull().sum()/data.isnull().count())*100).sort_values(ascending = False)
print("Total records = ", data.shape[0])
missing_data = pd.concat([total_null,percent.round(2)],axis=1,keys=['Total Missing','In percent'])
missing_data.head(10)

data.dropna(subset=['text'],inplace=True)

total_null=data.isnull().sum().sort_values(ascending=False)
percent = ((data.isnull().sum()/data.isnull().count())*100).sort_values(ascending = False)
print("Total records = ", data.shape[0])
missing_data = pd.concat([total_null,percent.round(2)],axis=1,keys=['Total Missing','In percent'])
missing_data.head(10)

train0=data[data['sentiment']=="Negative"]
train1=data[data['sentiment']=="Positive"]
train2=data[data['sentiment']=="Irrelevent"]
train3=data[data['sentiment']=="Neutral"]

train0.shape, train1.shape, train2.shape, train3.shape

train0.shape, train1.shape, train2.shape, train3.shape

data=pd.concat([train0,train1,train2,train3],axis=0)
data

id_types = data['id'].value_counts()
id_types

plt.figure(figsize=(12,7))
sns.barplot(x=id_types.values,y=id_types.index)

plt.xlabel('Type')
plt.ylabel('Count')
plt.title('# of Tv shows vs Movies')
plt.show()

game_types = data['game'].value_counts()
game_types

plt.figure(figsize=(12,7))
sns.barplot(x=game_types.values,y=game_types.index)

plt.xlabel('Type')
plt.ylabel('Count')
plt.title('# of Tv shows vs Movies')
plt.show()

sentiment_types = data['sentiment'].value_counts()
sentiment_types

plt.figure(figsize=(12,7))
plt.pie(x=sentiment_types.values,labels=sentiment_types.index)
plt.title('The Difference in the Type of Contents')
plt.show()

sns.catplot(x='game',hue='sentiment',kind='count',height=7,aspect=2,data=data)

from sklearn import preprocessing
label_encoder = preprocessing.LabelEncoder()

data['sentiment']=label_encoder.fit_transform(data['sentiment'])
data['game']=label_encoder.fit_transform(data['game'])
v_data['sentiment']=label_encoder.fit_transform(v_data['sentiment'])
v_data['game']=label_encoder.fit_transform(v_data['game'])

data = data.drop(['id'],axis=1)

data

data.nunique()

v_data.nunique()

